version: '3.8'

networks:
  lake-solution:
    driver: bridge

services:
  zookeeper:
    container_name: cdc_zookeeper
    image: confluentinc/cp-zookeeper:7.5.0
    ports:
      - 2181:2181
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    networks:
      - lake-solution

  kafka:
    container_name: cdc_kafka
    image: confluentinc/cp-kafka:7.5.0
    ports:
      - 9092:9092
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      - lake-solution

  kafka_connect_source:
    container_name: cdc_kafka_connect_source
    build: .
    ports:
      - 8083:8083
    depends_on:
      - kafka
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: 1
      CONFIG_STORAGE_TOPIC: connect_source_configs
      OFFSET_STORAGE_TOPIC: connect_source_offsets
      STATUS_STORAGE_TOPIC: connect_source_statuses
    networks:
      - lake-solution
    command:
      - bash
      - -c
      - |
        echo "Launching Kafka Connect worker"
        /docker-entrypoint.sh start & 

        echo "Waiting for Kafka Connect to start listening on localhost:8083 ⏳"
        while : ; do
            curl_status=$$(curl -s -o /dev/null -w %{http_code} http://localhost:8083/connectors)
            echo -e $$(date) " Kafka Connect listener HTTP state: " $$curl_status " (waiting for 200)"
            if [ $$curl_status -eq 200 ] ; then
            break
            fi
            sleep 5
        done

        sleep 25

        echo -e "\n--\n+> Creating Kafka Connect source connectors"
        curl -i -X POST -H "Accept:application/json" \
          -H "Content-Type:application/json" \
          localhost:8083/connectors/ \
          -d @/mysql_connector.json
        
        sleep infinity

  kafka_connect_sink:
    container_name: cdc_kafka_connect_sink
    image: confluentinc/cp-kafka-connect:7.5.0
    ports:
      - 8084:8083
    depends_on:
      - kafka
    env_file:
      - ../.env
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka:9092
      CONNECT_GROUP_ID: 2
      CONNECT_CONFIG_STORAGE_TOPIC: connect_sink_configs
      CONNECT_OFFSET_STORAGE_TOPIC: connect_sink_offsets
      CONNECT_STATUS_STORAGE_TOPIC: connect_sink_statuses
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_REST_ADVERTISED_HOST_NAME: localhost
      CONNECT_PLUGIN_PATH: /usr/share/confluent-hub-components
      CONNECT_REPLICATION_FACTOR: 1
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
    networks:
      - lake-solution
    command:
      - bash
      - -c
      - |
        echo -e "\n Installing Connector"
        confluent-hub install --no-prompt confluentinc/kafka-connect-s3:10.5.0
        
        echo "Launching Kafka Connect worker"
        /etc/confluent/docker/run &

        echo "Waiting for Kafka Connect to start listening on localhost:8083 ⏳"
        while : ; do
            curl_status=$$(curl -s -o /dev/null -w %{http_code} http://localhost:8083/connectors)
            echo -e $$(date) " Kafka Connect listener HTTP state: " $$curl_status " (waiting for 200)"
            if [ $$curl_status -eq 200 ] ; then
            break
            fi
            sleep 5
        done

        echo -e "\n--\n+> Creating Kafka Connect sink connectors"
        curl -i -X PUT -H  "Content-Type:application/json" \
          http://localhost:8083/connectors/s3-connector/config \
          -d '{
            "connector.class": "io.confluent.connect.s3.S3SinkConnector",
            "tasks.max": "1",
            "topics": "mysqlsales.lake_solution.sales",
            "s3.region": "us-east-1",
            "s3.bucket.name": "lake-solution",
            "flush.size": "1",
            "storage.class": "io.confluent.connect.s3.storage.S3Storage",
            "format.class": "io.confluent.connect.s3.format.parquet.ParquetFormat",
            "schema.generator.class": "io.confluent.connect.storage.hive.schema.DefaultSchemaGenerator",
            "partitioner.class": "io.confluent.connect.storage.partitioner.DefaultPartitioner",
            "name": "s3-connector"
          }'
        
        sleep infinity
